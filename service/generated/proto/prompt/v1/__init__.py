# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: proto/prompt/v1/prompt.proto
# plugin: python-betterproto
# This file has been @generated

from dataclasses import dataclass
from typing import List

import betterproto


class Role(betterproto.Enum):
    """Role is the role of the speaker."""

    ROLE_UNSPECIFIED = 0
    """Unspecified role. This is an error."""

    USER = 1
    """The user is speaking."""

    ASSISTANT = 2
    """The assistant is speaking."""


@dataclass(eq=False, repr=False)
class StartCompletionRequest(betterproto.Message):
    """
    StartCompletionRequest is a request to a large-language model to complete a
    conversation. There are one or more Stanza messages in the request, each
    representing a turn in the conversation.
    """

    stanzas: List["Stanza"] = betterproto.message_field(1)
    """The conversation to complete."""


@dataclass(eq=False, repr=False)
class ContinueCompletionRequest(betterproto.Message):
    """
    ContinueCompletionRequest is a request to a large-language model to
    continue a conversation.
    """

    conversation_id: str = betterproto.string_field(1)
    """
    Conversation identifier for the response. This helps the client match the
    response to the request.
    """

    counter: int = betterproto.int32_field(2)
    """
    Counter is the index of this request in the total stream of requests from
    which to continue the conversation. This is useful for clients that get
    disconnected and need to resume the conversation.
    """


@dataclass(eq=False, repr=False)
class CompletionResponse(betterproto.Message):
    """
    CompletionResponse is a response from a large-language model to a
    CompletionRequest. By definition the assistant is responding. Recall that
    the model streams a set of strings as a response. If this is the end of the
    response, the `is_final` field will be set to true.
    """

    conversation_id: str = betterproto.string_field(1)
    """
    Conversation identifier for the response. This helps the client match the
    response to the request.
    """

    text: str = betterproto.string_field(2)
    """The response from the model."""

    counter: int = betterproto.int32_field(3)
    """
    Counter is the index of this response in the total stream of responses.
    This is useful for clients that get disconnected and need to resume the
    conversation.
    """

    is_final: bool = betterproto.bool_field(4)
    """Whether this is the final response from the model."""


@dataclass(eq=False, repr=False)
class GetConversationRequest(betterproto.Message):
    """GetConversationRequest is a request to get a conversation."""

    conversation_id: str = betterproto.string_field(1)
    """
    Conversation identifier for the response. This helps the client match the
    response to the request.
    """


@dataclass(eq=False, repr=False)
class GetConversationResponse(betterproto.Message):
    """
    GetConversationResponse is a response from a large-language model to a
    GetConversationRequest.
    """

    stanza: List["Stanza"] = betterproto.message_field(1)
    """The conversation."""


@dataclass(eq=False, repr=False)
class Stanza(betterproto.Message):
    """Stanza is a turn in the conversation."""

    content: str = betterproto.string_field(1)
    """The text of the conversation."""

    role: "Role" = betterproto.enum_field(2)
    """The role of the speaker."""
